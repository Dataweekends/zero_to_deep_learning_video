{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data('/tmp/mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28*28)\n",
    "X_test = X_test.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "\n",
    "# K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit(X_train, y_train_cat, batch_size=128, epochs=10, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h.history['accuracy'])\n",
    "plt.plot(h.history['val_accuracy'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = model.evaluate(X_test, y_test_cat)[1]\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(10, size=(2, 3, 4, 5))\n",
    "B = np.random.randint(10, size=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[0, 1, 0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A random colored image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.random.randint(255, size=(4, 4, 3), dtype='uint8')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.subplot(221)\n",
    "plt.imshow(img)\n",
    "plt.title(\"All Channels combined\")\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(img[:, : , 0], cmap='Reds')\n",
    "plt.title(\"Red channel\")\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(img[:, : , 1], cmap='Greens')\n",
    "plt.title(\"Green channel\")\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.imshow(img[:, : , 2], cmap='Blues')\n",
    "plt.title(\"Blue channel\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A + A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tensordot(A, B, axes=([0, 1], [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tensordot(A, B, axes=([0], [0])).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([-1, 1], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.convolve(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.plot(a, 'o-')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(c, 'o-');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image filters with convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import convolve\n",
    "from scipy.signal import convolve2d\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = misc.ascent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_kernel = np.array([[ 1,  2,  1],\n",
    "                     [ 0,  0,  0],\n",
    "                     [-1, -2, -1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(h_kernel, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = convolve2d(img, h_kernel)\n",
    "\n",
    "plt.imshow(res, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(img, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = img.reshape((1, 512, 512, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3, 3), strides=(2,1), input_shape=(512, 512, 1)))\n",
    "model.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred_tensor = model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred = img_pred_tensor[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_pred, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(weights[0][:, :, 0, 0], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[0] = np.ones(weights[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred_tensor = model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred = img_pred_tensor[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_pred, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3, 3), input_shape=(512, 512, 1), padding='same'))\n",
    "model.compile('adam', 'mse')\n",
    "\n",
    "img_pred_tensor = model.predict(img_tensor)\n",
    "\n",
    "\n",
    "img_pred_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPool2D, AvgPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(MaxPool2D((5, 5), input_shape=(512, 512, 1)))\n",
    "model.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred = model.predict(img_tensor)[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_pred, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(AvgPool2D((5, 5), input_shape=(512, 512, 1)))\n",
    "model.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred = model.predict(img_tensor)[0, :, :, 0]\n",
    "plt.imshow(img_pred, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train_cat, batch_size=128,\n",
    "          epochs=2, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test_cat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 1\n",
    "You've been hired by a shipping company to overhaul the way they route mail, parcels and packages. They want to build an image recognition system  capable of recognizing the digits in the zipcode on a package, so that it can be automatically routed to the correct location.\n",
    "You are tasked to build the digit recognition system. Luckily, you can rely on the MNIST dataset for the intial training of your model!\n",
    "\n",
    "Build a deep convolutional neural network with at least two convolutional and two pooling layers before the fully connected layer.\n",
    "\n",
    "- Start from the network we have just built\n",
    "- Insert a `Conv2D` layer after the first `MaxPool2D`, give it 64 filters.\n",
    "- Insert a `MaxPool2D` after that one\n",
    "- Insert an `Activation` layer\n",
    "- retrain the model\n",
    "- does performance improve?\n",
    "- how many parameters does this new model have? More or less than the previous model? Why?\n",
    "- how long did this second model take to train? Longer or shorter than the previous model? Why?\n",
    "- did it perform better or worse than the previous model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data(('/tmp/mnist.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "329/329 [==============================] - 7s 20ms/step - loss: 0.2476 - accuracy: 0.9246 - val_loss: 0.0891 - val_accuracy: 0.9729\n",
      "Epoch 2/2\n",
      "329/329 [==============================] - 11s 33ms/step - loss: 0.0642 - accuracy: 0.9799 - val_loss: 0.0671 - val_accuracy: 0.9797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19f92b23a60>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_cat, batch_size=128, epochs=2, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05390630662441254, 0.982200026512146]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Pleased with your performance with the digits recognition task, your boss decides to challenge you with a harder task. Their online branch allows people to upload images to a website that generates and prints a postcard that is shipped to destination. Your boss would like to know what images people are loading on the site in order to provide targeted advertising on the same page, so he asks you to build an image recognition system capable of recognizing a few objects. Luckily for you, there's a dataset ready made with a collection of labeled images. This is the [Cifar 10 Dataset](http://www.cs.toronto.edu/~kriz/cifar.html), a very famous dataset that contains images for 10 different categories:\n",
    "\n",
    "- airplane \t\t\t\t\t\t\t\t\t\t\n",
    "- automobile \t\t\t\t\t\t\t\t\t\t\n",
    "- bird \t\t\t\t\t\t\t\t\t\t\n",
    "- cat \t\t\t\t\t\t\t\t\t\t\n",
    "- deer \t\t\t\t\t\t\t\t\t\t\n",
    "- dog \t\t\t\t\t\t\t\t\t\t\n",
    "- frog \t\t\t\t\t\t\t\t\t\t\n",
    "- horse \t\t\t\t\t\t\t\t\t\t\n",
    "- ship \t\t\t\t\t\t\t\t\t\t\n",
    "- truck\n",
    "\n",
    "In this exercise we will reach the limit of what you can achieve on your laptop and get ready for the next session on cloud GPUs.\n",
    "\n",
    "Here's what you have to do:\n",
    "- load the cifar10 dataset using `keras.datasets.cifar10.load_data()`\n",
    "- display a few images, see how hard/easy it is for you to recognize an object with such low resolution\n",
    "- check the shape of X_train, does it need reshape?\n",
    "- check the scale of X_train, does it need rescaling?\n",
    "- check the shape of y_train, does it need reshape?\n",
    "- build a model with the following architecture, and choose the parameters and activation functions for each of the layers:\n",
    "    - conv2d\n",
    "    - conv2d\n",
    "    - maxpool\n",
    "    - conv2d\n",
    "    - conv2d\n",
    "    - maxpool\n",
    "    - flatten\n",
    "    - dense\n",
    "    - output\n",
    "- compile the model and check the number of parameters\n",
    "- attempt to train the model with the optimizer of your choice. How fast does training proceed?\n",
    "- If training is too slow (as expected) stop the execution and move to the next session!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d461fe4ac0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_cat, batch_size=32, epochs=2, validation_data=(X_test, y_test_cat), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ea977d3a9fefc86bb4287da3ba2a65271e6d46d2415b19d8401e8ad88dd40d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
